{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caesarcc/python-tcc-url-fakenews-check/blob/main/jupyter/passo05_preditor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q lime"
      ],
      "metadata": {
        "id": "gQoYJ0FvIvUo",
        "outputId": "f55288c9-7b15-4bc7-e4d2-c449b9883ed1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.2 MB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 54.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 43.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 275 kB 5.1 MB/s \n",
            "\u001b[?25h  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7ZLDy5a-Lh-g",
        "outputId": "e7ccc0e1-61be-4e74-b728-d56a11c80dda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KWLog7Om85PW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import hashlib\n",
        "import torch\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "from scipy.special import softmax\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "from transformers.file_utils import is_torch_available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "k9lpflar85Pe"
      },
      "outputs": [],
      "source": [
        "MODELO_BERT = \"/content/drive/MyDrive/PUC/TCC/modelos/bertimbau_avaliar_noticias\"\n",
        "model = BertForSequenceClassification.from_pretrained(MODELO_BERT, num_labels=2, output_attentions=False, output_hidden_states=False)\n",
        "tokenizer = BertTokenizer.from_pretrained(MODELO_BERT, do_lower_case=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL8ZUHev85Pf"
      },
      "source": [
        "Preditor deve antes de rodar modelo<br>\n",
        "> Limpar texto<br>\n",
        "> Remover stopwords<br>\n",
        "> Lematizar<br>\n",
        "-- Caso o texto seja maior que 400 palavras<br>\n",
        "> Sumarizar texto (sem lematizaÃ§Ã£o e com stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PyOj_f0T85Pj",
        "outputId": "8f562398-e41c-4e36-a755-af71d9eccf38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "def qual_device():\n",
        "    if is_torch_available() and torch.cuda.is_available():\n",
        "        return \"cuda\"\n",
        "    return \"cpu\"\n",
        "qual_device()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(qual_device())\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "aGhMe-K4M24j",
        "outputId": "704052ca-b8bc-497b-c925-1db843167f00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "1PDjvrXd85Pl"
      },
      "outputs": [],
      "source": [
        "def explicar(texto, classes):\n",
        "    def prever_explicando(texto):\n",
        "        temp = pd.DataFrame(texto, columns = ['texto'])\n",
        "        temp['tokens'] = temp['texto'].apply(lambda x: np.array(tokenizer.encode(x, add_special_tokens=True, max_length=400, padding='max_length', truncation=True)))\n",
        "        valores = torch.tensor(np.array(temp['tokens'].values.tolist())).to(torch.int64)\n",
        "        valores = valores.to(qual_device())\n",
        "        resultados = []\n",
        "        for valor in valores:\n",
        "            with torch.no_grad():\n",
        "                outputs = model(valor.unsqueeze(0), token_type_ids=None)\n",
        "            logits = outputs.logits.cpu().detach().numpy()\n",
        "            logits = softmax(logits)\n",
        "            resultados.append(logits[0])\n",
        "        retorno = np.array(resultados)\n",
        "        return retorno    \n",
        "    explainer = LimeTextExplainer(class_names=classes)\n",
        "    exp = explainer.explain_instance(texto, prever_explicando)\n",
        "    exp.save_to_file(f'{hashlib.md5(texto.encode()).hexdigest()}.html')\n",
        "    return exp.as_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "W8Il6HnM85Pm"
      },
      "outputs": [],
      "source": [
        "def prever(texto, classes):\n",
        "    tokens = tokenizer.encode(texto, padding='max_length', truncation=True, max_length=400)\n",
        "    valores = torch.tensor(tokens).to(qual_device())\n",
        "    with torch.no_grad():\n",
        "        outputs = model(valores.unsqueeze(0), token_type_ids=None)\n",
        "    classes_previstas = outputs.logits.detach().cpu().numpy()\n",
        "    predicao = np.argmax(classes_previstas, axis=1).flatten()\n",
        "    return softmax(classes_previstas), predicao"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "def prever_novo(texto, classes):\n",
        "    encoded_review = tokenizer.encode_plus(\n",
        "        texto,\n",
        "        max_length=400,\n",
        "        add_special_tokens=True,\n",
        "        return_token_type_ids=False,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt',\n",
        "      )\n",
        "\n",
        "    input_ids = encoded_review['input_ids'].to(qual_device())\n",
        "    attention_mask = encoded_review['attention_mask'].to(qual_device())\n",
        "\n",
        "    output = model(input_ids, attention_mask).logits\n",
        "    _, prediction = torch.max(output, dim=1)\n",
        "    probs = F.softmax(output, dim=1)\n",
        "\n",
        "    print(pd.DataFrame(probs.tolist()[0], classes)[0])\n"
      ],
      "metadata": {
        "id": "y_kW1oich2vN"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "gQgzvWxe85Po",
        "outputId": "3848fc16-2273-45eb-be51-685ee7f2d3cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confiável    0.001938\n",
            "Falso        0.998062\n",
            "Name: 0, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "classes = ['Confiável','Falso']\n",
        "texto = \"\"\"O popular apresentador Ratinho foi ví­tima de um acidente de carro com toda a sua família em São Paulo, \n",
        "e infelizmente não resistiu aos ferimentos e morreu\"\"\"\n",
        "prever_novo(texto, classes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"\"\"Dicionário Oscar : categoria técnico premir ? . Conheça prêmios Melhor fotografia , edição design produção – glamurosos , \n",
        "responsável reconhecer centena profissional trabalhar trás câmeras.\"\"\"\n",
        "prever_novo(texto, classes)"
      ],
      "metadata": {
        "id": "VdmowmTnY7Zy",
        "outputId": "24f44846-9012-4b33-943c-ab7e90e31182",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confiável    0.97017\n",
            "Falso        0.02983\n",
            "Name: 0, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.encode(texto, padding='max_length', truncation=True, max_length=400)\n",
        "valores = torch.tensor(tokens).to(qual_device())\n",
        "valores.unsqueeze(0)"
      ],
      "metadata": {
        "id": "W_9SnbhqgQ-E",
        "outputId": "588d6c07-05a4-4abe-b32c-88d4c2ebd83a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,   200, 16484, 18868, 18199, 22317,   118,  5857,  1564,   790,\n",
              "           333, 11407, 22278,   171, 14081,   117,   123,  7347, 22278,   461,\n",
              "         22303,  2916, 13553,   113,   267, 22317,   114,  6454,   260,  4739,\n",
              "          3290,   221, 13142, 22282,   146,  1640,  7435, 18286,   119, 16663,\n",
              "          4820,   123,  6698,   171,  1640,   117,   179,  2471, 17293,  1555,\n",
              "           125, 14651,   110,   180,  1521,   117,   123,  7347, 22278,  2694,\n",
              "           179, 18286,   346,  4737,   176, 12439, 22282,   298,  3955, 11720,\n",
              "         11735, 22281,   240,   347,  1161,   119,   107, 13716,   259,   126,\n",
              "          1913,   501, 19673, 22281,   180,  3338,   146, 18286,  4737, 20327,\n",
              "          8807,   119,   989,   146,  3901,   437, 14151,   181,   320,  3811,\n",
              "           119,  7178, 11989,   243,   107,   117,  3415,   119,   231,  3101,\n",
              "           125,   989,   478,   171, 14081,  3368, 11407,   159,   461, 22303,\n",
              "          2916, 13553,   229,  6151,   118, 14258,   117,  2506,   119,   177,\n",
              "          3659,   262,  1334,  1378,   125, 11007,   423,  1640,   171,  3243,\n",
              "           117,  7347,  8905,  1080,  1613,  7775,   113,   257, 22322,   114,\n",
              "           117,   179, 10789,   123,  3087,   240,  1423,   125,  4428,   353,\n",
              "          4471,   119,   107,  3544,   553,   436,   940,  2171,   125, 20655,\n",
              "           171,  3243,   107,   117,  3415,   119,   335, 16677,   353,  4471,\n",
              "           117,   461, 22303,  2916, 13553,  1996,   179,   262, 11407, 22278,\n",
              "           240,   107,  6209,  5676,   179, 16550,   671,   288,   107,   320,\n",
              "          1161,   119,   107,  2054, 22283, 11407, 22278,  8462,   240,   346,\n",
              "           370,  2160,  9359,   353, 13886,   229,  1837,   119,  2054, 22283,\n",
              "         11407, 22278,   240,  6209,  5676,   179, 16550,   671, 22287,   320,\n",
              "          1161,   119,  2054, 22283, 11407, 22278,  1502, 15590,   244,  4640,\n",
              "           346,   123,  7744,   117, 17327,   291,   494,  8397,   138,   171,\n",
              "           926,   107,   117,  3415,   119,  2258,  4739,  3290,   117,   461,\n",
              "         22303,  2916, 14000,   179, 10182,   412, 10544,   202,  3243,   117,\n",
              "           107,   449,   259,  4063,  1499,   382, 15469,   107,   119,  1263,\n",
              "           644,   700,   180, 14939,   117,   123,   294,   118,  1640, 12897,\n",
              "         18244,  4274,  2070, 10109,   173,  2347,   353,  7347, 22278,   173,\n",
              "           347, 12243,   119,  1660,  8604,   179,   123,  3659,   262,   230,\n",
              "          5597,   598,   259,  4594,   119,   107,   177, 14939,   180,  7347,\n",
              "         22278,   461, 22303,  2916, 13553,   171, 14081,   253,   230,  5597,\n",
              "           598,   259,   532,  9615,   171, 14278,   122,   598,   259,  4594,\n",
              "           125,   944,   259,  3545,   179,   123, 16598, 22287,   122,  8296,\n",
              "         22287,   107,   117,  2694,   123,   766, 10225,   119, 12897,   407,\n",
              "          3415,   179,   146, 14081,  2137,  4537,   307,  4043,   107, 21418,\n",
              "           117,  3578,  8012, 22281,   122,  6939,   676,   107,   119,   102,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "ELlEC5H485Pr",
        "outputId": "85a0c8bd-3039-4017-eb14-73415c4f1549",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.06074722, 0.9392526 ]], dtype=float32), array([1]))"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "prever(texto, classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "5iR6xL_R85Ps",
        "outputId": "5cd9f7f8-7ce6-4a88-d20f-014432abd7a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Brasil', 0.15024944879834823),\n",
              " ('essas', 0.13739181909935577),\n",
              " ('portuguesa', 0.1356705543994631),\n",
              " ('pela', 0.0836190754914776),\n",
              " ('muito', 0.08183565436870122),\n",
              " ('vão', 0.07911594281843873),\n",
              " ('e', 0.07872064933299759),\n",
              " ('similaridades', -0.06427648529743125),\n",
              " ('histórico', -0.03143715967272221),\n",
              " ('comum', -0.02742048612767332)]"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "explicar(texto, classes)    "
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "50691a0bc379e9e647c9463feff34781ae883c7b810726d51a7ed60c4a02b637"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('tcc')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "name": "passo05_preditor.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}